{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT MINING for BEGINNER\n",
    "- 본 자료는 텍스트 마이닝을 활용한 연구 및 강의를 위한 목적으로 제작되었습니다.\n",
    "- 본 자료의 허가되지 않은 배포를 금지합니다.\n",
    "- 저작권, 출판, 특허, 공동저자에 관련해서는 따로 문의 바랍니다.\n",
    "- **Contact : 전병진(fingeredman@gmail.com)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DAY 06. 정적 페이지 수집하기: 실시간검색어, 영화댓글\n",
    "- Python을 활용해 단순한 웹페이지에서 데이터를 크롤링하는 방법에 대해 다룹니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **\\*\\*\\* 주의사항 \\*\\*\\***  \n",
    "본 자료에서 설명하는 웹크롤링하는 방법은 해당 기법에 대한 이해를 돕고자하는 교육의 목적으로 사용되었으며,  \n",
    "이를 활용한 대량의 무단 크롤링은 범죄에 해당할 수 있음을 알려드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1. 네이버 영화댓글을 대량으로 가져오기\n",
    "> - 본 자료를 응용하여 네이버 영화댓글을 부가정보와 함께 대량으로 가져오는 코드를 작성합니다.\n",
    "- 영화댓글 페이지의 100페이지 분량의 댓글을 수집합니다.\n",
    "- 영화댓글 텍스트와 함께, 작성일자와 평점을 같이 가져옵니다.\n",
    "- 영화댓글, 작성일자, 평점을 탭(\\t) 단위로 구분하여 파일에 저장합니다.  \n",
    "\n",
    "> HINT. 영화댓글 URL 맨 뒤의 숫자는 페이지 번호를 의미합니다. (\"&page=1\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\r"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib\n",
    "\n",
    "PAGE_LIMIT = 100\n",
    "URL = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=132623&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=\"\n",
    "SAVE_FILE_PATH = \"captin_marvel.txt\"\n",
    "\n",
    "f = open(SAVE_FILE_PATH, \"w\", encoding=\"utf-8\")\n",
    "for page in range(1, PAGE_LIMIT+1):\n",
    "    print(page, end=\"\\r\")\n",
    "    url = URL + str(page)\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    comments = soup.findAll('div', {'class':'score_reple',})\n",
    "    comment = [tag.p for tag in comments]\n",
    "    for c in comment:\n",
    "        f.write(c.get_text() + \"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
